{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srFVYE4vluJ2"
      },
      "source": [
        "#### All imports here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFMFjoKkluJ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghae6dKVluJ4"
      },
      "source": [
        "#### Reading data set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the purpose of the project, I imported the file from my google drive while using google colab.\n",
        "# I have added the dataset file 'yahoo_dataset.csv' in the github repo.\n",
        "# However, if you still wish to access the file from your google drive, then\n",
        "# you can execute the following code on google colab signed into the same account\n",
        "# as the google drive that you wish to access.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-D_sUosl7Iv",
        "outputId": "b939028a-9af8-426d-c7a4-f8d19fe8d905"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/infinite-data/history.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3w0jXXhl8G-",
        "outputId": "90ac8d69-27d2-447d-fcd7-c58dd8ca0882"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-1220a43f522c>:2: DtypeWarning: Columns (87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_data = pd.read_csv('/content/drive/MyDrive/infinite-data/history.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBOuIIxpluJ5"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"./datasets/history.csv\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ncXCheTluJ5"
      },
      "outputs": [],
      "source": [
        "info_df = pd.read_csv(\"account_data_info.csv\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "info_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1fZp9TluJ5"
      },
      "source": [
        "#### Dropping Columns and Research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jN4NTECBluJ5"
      },
      "outputs": [],
      "source": [
        "# Aditya Parekh:\n",
        "# I am removing these columns because they have 600k+ NULL values.\n",
        "rem_cols_na = ['country_code', 'cashflows_custody_fee', 'arp_pension_origin', 'sss_location']\n",
        "# I am removing these columns because they have 0 NULL values, but only one unique value.\n",
        "rem_cols_one_uniq = ['net_of_fees', 'fee_paid_separately', 'custody_fee_withdrawal', 'is_fee_exempt']\n",
        "# The following columns are NULL when 'class_id' = NULL. DON'T REMOVE THESE YET.\n",
        "null_3198_cols = ['debit_code', 'last_trade_date', 'contract_type', 'inception_date',\n",
        "             'branch', 'credit_limit_type', 'retail_plan', 'language_code', 'dividend_confirm_code']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jZW54nXxluJ6"
      },
      "outputs": [],
      "source": [
        "# Aditya Mani:\n",
        "# 1. esir_number: Contains 673327 missing values and cannot be imputed (has very little unique values)\n",
        "# 2. shareholder_language: Contains 623554 missing values. Says whether the shareholder speaks English or French and there seems to be an equal proportion.\n",
        "# 3. has_no_min_commission: No Null values and only 1 unique value.\n",
        "# 4. rep_commission_rate: 1 unique value and few missing values that cannot be imputed.\n",
        "# 5. spousal_age_flag: No Null values and only 1 unique value.\n",
        "# 6. is_parameters_account: No Null values and only 1 unique value.\n",
        "# 7. rrsp_limit_reached: No Null values and only 1 unique value.\n",
        "# 8. is_portfolio_account: No Null values and only 1 unique value.\n",
        "# 9. sss_type: Lot of missing values\n",
        "# 10. sss_agent: Lot of missing values\n",
        "# 11. target_grantor_grantee_flag: Missing values\n",
        "# 12. terminal_code: Missing values\n",
        "\n",
        "to_drop = ['esir_number', 'shareholder_language', 'has_no_min_commission', 'rep_commission_rate',\n",
        "           'spousal_age_flag', 'is_parameters_account', 'rrsp_limit_reached', 'is_portfolio_account',\n",
        "             'sss_type', 'sss_agent', 'target_grantor_grantee_flag', 'terminal_code']\n",
        "\n",
        "missing_3198 = ['options_trading_type',\n",
        " 'is_midwest_clearing_account',\n",
        " 'rep_commission_override',\n",
        " 'interest_dividend_conversion_type',\n",
        " 'guarantee_gtor_type',\n",
        " 'deceased_fair_market_value',\n",
        " 'iso_funds_code']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "MlG8WVTtluJ6"
      },
      "outputs": [],
      "source": [
        "# Jithin Krishna:\n",
        "\n",
        "# Has too many null values\n",
        "# last_update_date is the maintaineance date and was deemed not relevant to the churn\n",
        "drop_cols = [\"special_tag\", \"conjunction\", \"title\", \"function_code\" ,\"tms_settlement_location\", \"loan_limit_override\", \"last_update_date\"]\n",
        "\n",
        "# These values have 1 unique value and is not useful and hence shall be dropped\n",
        "drop_uniq_cols = [\"portfolio_cost_method\", \"portfolio_name_address_option\", \"portfolio_summary_option\",\"interactive_portfolio_code\"]\n",
        "\n",
        "drop_3198_cols = [\"portfolio_report_option\", \"mailing_consent\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4fGLG5s9luJ6"
      },
      "outputs": [],
      "source": [
        "# Srishti Prayag:\n",
        "# remove columns with more than 300,000 missing values\n",
        "too_many_nans = ['special_fee_code', 'resp_specimen_plan', 'plan_end_date', 'retail_last_maintenance_user']\n",
        "\n",
        "# list of columns with exactly 316985 missing values; may be connected so don't drop yet\n",
        "nan_316985_columns = ['is_pledged', 'non_calendar_year_end', 'plan_effective_date', 'is_resp', 'number_of_beneficiaries', 'rrif_original_date', 'use_original_date_for_payment_calc', 'is_family_resp', 'is_hrdc_resp', 'retail_last_maintenance_time']\n",
        "\n",
        "# list of columns with only 1 unique value\n",
        "only_one_unique = ['is_plan_grandfathered', 'is_gl_account', 'is_control_account']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "yvpASeFAluJ6"
      },
      "outputs": [],
      "source": [
        "rem_cols = []\n",
        "rem_cols.extend(rem_cols_na)\n",
        "rem_cols.extend(rem_cols_one_uniq)\n",
        "rem_cols.extend(to_drop)\n",
        "rem_cols.extend(drop_cols)\n",
        "rem_cols.extend(drop_uniq_cols)\n",
        "rem_cols.extend(too_many_nans)\n",
        "rem_cols.extend(only_one_unique)\n",
        "train_data = train_data.drop(rem_cols, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where column 'class_id' is NaN\n",
        "train_data = train_data.dropna(subset=['class_id'])"
      ],
      "metadata": {
        "id": "XkgANppImV8f"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv(\"./cleaned_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "552Dh3v91cz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D9jwG7ZN1sTi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}